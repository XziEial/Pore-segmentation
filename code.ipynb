{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a9c2728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #生成train、val、test的txt文件\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import os\n",
    "\n",
    "# imagedir = './dataset/2w_dataset/2w_image'\n",
    "# outdir = './dataset/2w_dataset'\n",
    "# os.makedirs(outdir,exist_ok=True)\n",
    "\n",
    "# images = []\n",
    "# for file in os.listdir(imagedir):\n",
    "#     filename = file.split('.')[0]\n",
    "#     images.append(filename)\n",
    "\n",
    "# # Split the data into training, validation, and test sets (8:1:1 ratio)\n",
    "# train_size = 0.8\n",
    "# val_size = 0.1\n",
    "# test_size = 0.1\n",
    "\n",
    "# train, temp = train_test_split(images, test_size=(val_size + test_size), random_state=100)\n",
    "# val, test = train_test_split(temp, test_size=(test_size / (val_size + test_size)), random_state=100)\n",
    "\n",
    "# # Write the lists to text files\n",
    "# with open(os.path.join(outdir, \"train.txt\"), 'w') as f:\n",
    "#     f.write('\\n'.join(train))\n",
    "\n",
    "# with open(os.path.join(outdir, \"val.txt\"), 'w') as f:\n",
    "#     f.write('\\n'.join(val))\n",
    "\n",
    "# with open(os.path.join(outdir, \"test.txt\"), 'w') as f:\n",
    "#     f.write('\\n'.join(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b492e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import glob\n",
    "import time\n",
    "import os\n",
    "from skimage.io import imread\n",
    "import copy\n",
    "import cv2 as cv\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "from unet import UNet\n",
    "from Models import Unet_dict, NestedUNet, U_Net, R2U_Net, AttU_Net, R2AttU_Net\n",
    "from ConvUNeXt import ConvUNeXt\n",
    "from SA_Unet import SA_UNet\n",
    "from RMA_UNet import RMA_UNet\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b5e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66523717",
   "metadata": {},
   "source": [
    "# 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6c68fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义读取图像的函数\n",
    "def read_image(root = './dataset/2w_dataset_revise/train.txt'):\n",
    "    image = np.loadtxt(root,dtype=str)\n",
    "    n = len(image)\n",
    "    data,label = [None]*n, [None]*n\n",
    "    for i, fname in enumerate(image):\n",
    "        data[i] = imread('./dataset/2w_dataset_revise/2w_image/%s.jpg' %(fname))\n",
    "        label[i] = imread('./dataset/2w_dataset_revise/2w_mask/%s.png' %(fname))\n",
    "    return data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858917a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取训练数据\n",
    "traindata,trainlabel = read_image(root = './dataset/2w_dataset_revise/train.txt')\n",
    "#读取验证数据集\n",
    "valdata,vallabel = read_image(root = './dataset/2w_dataset_revise/val.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca5f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看训练集和验证集的图像\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(traindata[0], cmap=plt.cm.gray)\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(trainlabel[0], cmap=plt.cm.gray)\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(valdata[0], cmap=plt.cm.gray)\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(vallabel[0], cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42a1ef9",
   "metadata": {},
   "source": [
    "# 处理图像标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e3683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#列出标签\n",
    "classes = ['background','pore']\n",
    "colormap = [[0, 0, 0], # 0 = background\n",
    "            [128, 0, 0]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219abebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将一个标记好的图像转化为类别标签图像\n",
    "def image2label(image, colormap):\n",
    "    # 每个像素点有 0 ~ 255 的选择，RGB 三个通道\n",
    "    cm2lbl = np.zeros(256**3)\n",
    "    # 枚举的时候i是下标，cm是一个三元组，分别标记了RGB值\n",
    "    for i,cm in enumerate(colormap):\n",
    "        cm2lbl[(cm[0]*256+cm[1]*256+cm[2])] = i    # 建立索引\n",
    "    # 对一张图像转换\n",
    "    image = np.array(image, dtype=\"int64\")\n",
    "    ix = (image[:,:,0]*256+image[:,:,1]*256+image[:,:,2])\n",
    "    image2 = cm2lbl[ix]\n",
    "    return image2\n",
    "\n",
    "\n",
    "# 单组图像的转换操作\n",
    "def img_transforms(data, label, colormap):\n",
    "# 数据的随机裁剪、将图像数据进行标准化、将标记图像数据进行二维标签化的操作，输出原始图像和类别标签的张量数据\n",
    "    data_tfs = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.446],\n",
    "#                              [0.182])])\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])])\n",
    "    data = data_tfs(data)\n",
    "    label = torch.from_numpy(image2label(label, colormap))\n",
    "    return data, label\n",
    "\n",
    "# # 定义需要读取的数据路径的函数\n",
    "# def read_image_path(root = './dataset/img_voc/train.txt'):\n",
    "# # 原始图像路径输出为data，标签图像路径输出为label\n",
    "#     image = np.loadtxt(root,dtype=str)\n",
    "#     n = len(image)\n",
    "#     data,label = [None]*n, [None]*n\n",
    "#     for i, fname in enumerate(image):\n",
    "#         data[i] = imread('./dataset/img_voc/JPEGImages/%s.jpg' %(fname))\n",
    "#         label[i] = imread('./dataset/img_voc/SegmentationClass/%s.png' %(fname))\n",
    "#     return data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7204533c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个MyDataset继承于torch.utils.data.Dataset类\n",
    "class MyDataset(Data.Dataset):\n",
    "    \"\"\"用于读取图像，并进行相应的裁剪等\"\"\"\n",
    "    def __init__(self, data_root, imtransform, colormap):\n",
    "        ## data_root:数据所对应的文件名\n",
    "        ## high,width:图像裁剪后的尺寸\n",
    "        ## imtransform:预处理操作\n",
    "        ## colormap:颜色\n",
    "        self.data_root = data_root\n",
    "        self.imtransform = imtransform\n",
    "        self.colormap = colormap\n",
    "        data_list, label_list = read_image(root=data_root)\n",
    "        self.data_list = data_list\n",
    "        self.label_list = label_list\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data_list[idx]\n",
    "        label = self.label_list[idx]\n",
    "        img = Image.fromarray(img).convert('RGB')\n",
    "        label = Image.fromarray(label)\n",
    "        img, label = self.imtransform(img, label, self.colormap)\n",
    "        return img,label\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e111eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "voc_train = MyDataset(\"./dataset/2w_dataset_revise/train.txt\", img_transforms, colormap)\n",
    "voc_val = MyDataset(\"./dataset/2w_dataset_revise/val.txt\", img_transforms, colormap)\n",
    "# 创建数据加载器每个batch使用4张图像\n",
    "train_loader = Data.DataLoader(voc_train, batch_size=8, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = Data.DataLoader(voc_val, batch_size=8, shuffle=True, num_workers=0, pin_memory=True)\n",
    "# 检查训练数据集的一个batch的样本的维度是否正确\n",
    "for step,(b_x,b_y) in enumerate(train_loader):\n",
    "    if step > 0:\n",
    "        break\n",
    "# 输出训练图像的尺寸和标签的尺寸，以及接受类型\n",
    "print(\"b_x.shape:\",b_x.shape)\n",
    "print(\"b_y.shape:\",b_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f45eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将标准化后的图像转化为0-1的区间\n",
    "def inv_normalize_image(data):\n",
    "    mean= np.array([0.446])\n",
    "    std = np.array([0.182])\n",
    "    data = data.astype('float32') * std + mean\n",
    "    return data.clip(0,1)\n",
    "\n",
    "# 从预测的标签转化为图像的操作\n",
    "def label2image(prelabel,colormap):\n",
    "    h,w = prelabel.shape\n",
    "    prelabel = prelabel.reshape(h*w, -1)\n",
    "    image = np.zeros((h*w, 3),dtype=\"int32\")\n",
    "    for ii in range(len(colormap)):\n",
    "        index = np.where(prelabel == ii)\n",
    "        image[index, :] = colormap[ii]\n",
    "    return image.reshape(h,w,3)\n",
    "\n",
    "# # 可视化一个batch的图像，检查数据预处理是否正确\n",
    "# b_x_numpy = b_x.data.numpy()\n",
    "# b_x_numpy = b_x_numpy.transpose(0,2,3,1)\n",
    "# b_y_numpy = b_y.data.numpy()\n",
    "# plt.figure(figsize=(16,6))\n",
    "# for ii in range(8):\n",
    "#     plt.subplot(2,8,ii+1)\n",
    "#     plt.imshow(inv_normalize_image(b_x_numpy[ii]))\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.subplot(2,8,ii+9)\n",
    "#     plt.imshow(label2image(b_y_numpy[ii],colormap))\n",
    "#     plt.axis(\"off\")\n",
    "# plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4741c9",
   "metadata": {},
   "source": [
    "# 网络搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3701bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RMA_UNet(3,2).to(device)\n",
    "# model = ConvUNeXt(3,2,32).to(device)\n",
    "# model = UNet(3, 2).to(device)\n",
    "# model = SA_UNet(3, 2).to(device)\n",
    "summary(model, input_size=(3, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2fc2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_accuracy(output, mask):\n",
    "    with torch.no_grad():\n",
    "        output = torch.argmax(F.softmax(output, dim=1), dim=1)\n",
    "        correct = torch.eq(output, mask).int()\n",
    "        accuracy = float(correct.sum()) / float(correct.numel())\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a168364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mIoU(pred_mask, mask, smooth=1e-10, n_classes=2):\n",
    "    with torch.no_grad():\n",
    "        pred_mask = F.softmax(pred_mask, dim=1)\n",
    "        pred_mask = torch.argmax(pred_mask, dim=1)\n",
    "        pred_mask = pred_mask.contiguous().view(-1)\n",
    "        mask = mask.contiguous().view(-1)\n",
    "\n",
    "        iou_per_class = []\n",
    "        for clas in range(1, n_classes): #loop per pixel class\n",
    "            true_class = pred_mask == clas\n",
    "            true_label = mask == clas\n",
    "\n",
    "            if true_label.long().sum().item() == 0: #no exist label in this loop\n",
    "                iou_per_class.append(np.nan)\n",
    "            else:\n",
    "                intersect = torch.logical_and(true_class, true_label).sum().float().item()\n",
    "                union = torch.logical_or(true_class, true_label).sum().float().item()\n",
    "\n",
    "                iou = (intersect + smooth) / (union +smooth)\n",
    "                iou_per_class.append(iou)\n",
    "        return np.nanmean(iou_per_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050050e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, traindataloader, valdataloader, num_epochs):\n",
    "    \"\"\"\n",
    "    :param model: 网络模型\n",
    "    :param criterion: 损失函数\n",
    "    :param optimizer: 优化函数\n",
    "    :param traindataloader: 训练的数据集\n",
    "    :param valdataloader: 验证的数据集\n",
    "    :param num_epochs: 训练的轮数\n",
    "    \"\"\"\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "    \n",
    "    train_loss_all = []\n",
    "    train_acc_all = []\n",
    "    train_iou_all = []\n",
    "    \n",
    "    val_loss_all = []\n",
    "    val_acc_all = []\n",
    "    val_iou_all = []\n",
    "    \n",
    "    lr_list = []\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        train_loss = 0.0\n",
    "        train_num = 0\n",
    "        train_acc = 0\n",
    "        train_iou = 0\n",
    "        \n",
    "        val_loss = 0.0\n",
    "        val_num = 0\n",
    "        val_acc = 0\n",
    "        val_iou = 0\n",
    "        ## 每个epoch包括训练和验证阶段\n",
    "        model.train()  ## 设置模型为训练模式\n",
    "        for step,(b_x,b_y) in enumerate(traindataloader):\n",
    "            optimizer.zero_grad()\n",
    "            b_x = b_x.float().to(device)\n",
    "            b_y = b_y.long().to(device)\n",
    "            out = model(b_x)\n",
    "#             out = torch.argmax(F.softmax(out, dim=1), dim=1)\n",
    "            loss = criterion(out, b_y) ## 计算损失函数值\n",
    "            train_acc += pixel_accuracy(out, b_y)\n",
    "            train_iou += mIoU(out, b_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "#             lr_list.append(optimizer.param_groups[0]['lr'])\n",
    "            train_loss += loss.item() * len(b_y)\n",
    "            train_num += len(b_y)\n",
    "        scheduler.step()\n",
    "            \n",
    "\n",
    "        ## 计算一个epoch在训练集上的损失和精度\n",
    "        lr_list.append(optimizer.state_dict()['param_groups'][0]['lr'])\n",
    "        train_loss_all.append(train_loss / train_num)\n",
    "        train_acc_all.append(train_acc/len(traindataloader))\n",
    "        train_iou_all.append(train_iou/len(traindataloader))\n",
    "        print('Epoch:{} | Train loss\"{:.5f} | Train ACC:{:.5f} | Train Iou:{:.5f}'.format(epoch, train_loss_all[-1], train_acc/len(traindataloader), train_iou/len(traindataloader)))\n",
    "\n",
    "        ## 计算一个epoch训练后在验证集上的损失\n",
    "        model.eval() ## 设置模型为验证模式\n",
    "        for step,(b_x,b_y) in enumerate(valdataloader):\n",
    "            b_x = b_x.float().to(device)\n",
    "            b_y = b_y.long().to(device)\n",
    "            out = model(b_x)\n",
    "#             out = torch.argmax(F.softmax(out, dim=1), dim=1)\n",
    "            loss = criterion(out, b_y) ## 计算损失函数值\n",
    "            val_acc += pixel_accuracy(out, b_y)\n",
    "            val_iou += mIoU(out, b_y)\n",
    "            val_loss += loss.item() * len(b_y)\n",
    "            val_num += len(b_y)\n",
    "#             scheduler.step(val_loss)\n",
    "            \n",
    "        ## 计算一个epoch在验证集上的损失和精度\n",
    "        val_loss_all.append(val_loss / val_num)\n",
    "        val_acc_all.append(val_acc/len(valdataloader))\n",
    "        val_iou_all.append(val_iou/len(valdataloader))\n",
    "        print('Epoch:{} | Val loss\"{:.5f} | Val ACC:{:.5f} | Val Iou:{:.5f}'.format(epoch, val_loss_all[-1], val_acc/len(valdataloader), val_iou/len(valdataloader)))\n",
    "\n",
    "        ## 保存最好的网络参数\n",
    "        if val_loss_all[-1] < best_loss:\n",
    "            best_loss = val_loss_all[-1]\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "#         scheduler.step(val_loss_all[-1])\n",
    "        \n",
    "        ## 每个epoch花费的时间\n",
    "        time_use = time.time() - start\n",
    "        print(\"Train and val complete in {:.0f}m {:.0f}s\".format(time_use // 60, time_use %60))\n",
    "\n",
    "        data = {\"epoch\":range(num_epochs),\n",
    "                \"train_loss_all\":train_loss_all,\n",
    "                \"train_acc_all\":train_acc_all,\n",
    "                \"train_iou_all\":train_iou_all,\n",
    "                \"val_loss_all\":val_loss_all,\n",
    "                \"val_acc_all\":val_acc_all,\n",
    "                \"val_iou_all\":val_iou_all,\n",
    "                \"lr_list\":lr_list}\n",
    "    ## 输出最好的模型\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model,data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3622687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-8, weight_decay=1e-4)\n",
    "scheduler=torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115e1d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model,data = train_model(model,criterion,optimizer,scheduler,train_loader,val_loader, num_epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc8693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,\"RMA_UNet.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29151723",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(data,\"RMA_UNet_data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1937b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
